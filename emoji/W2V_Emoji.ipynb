{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cd-QdGUpU2uF"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install emoji"
   ],
   "metadata": {
    "id": "MUlbSSQQWAVb",
    "outputId": "4b89942c-d547-441f-9dcf-2ec12a1e3802",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (2.9.0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install umap"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_wTyyiKbc6Th",
    "outputId": "5d5a50c9-c4ba-472a-cf74-a3c9a0213a04"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: umap in /usr/local/lib/python3.10/dist-packages (0.1.1)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install imojify"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kVJ7qI5UdABM",
    "outputId": "88a21113-f42e-4a94-df4f-df38f98badfe"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: imojify in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
      "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from imojify) (2.9.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imojify) (1.23.5)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from imojify) (9.4.0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6kgOTnzjU2S9"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install emoji"
   ],
   "metadata": {
    "id": "-XVWd6MRMX99"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "from gensim.models import Word2Vec"
   ],
   "metadata": {
    "id": "CgFlK55-C_EM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Za67KjbCvPJz"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Word2Vect w/ Emojis"
   ],
   "metadata": {
    "id": "L8dZ9v_jV1ci"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mapping"
   ],
   "metadata": {
    "id": "ktRezsj-Wb9x"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SxGaRdG5VMab"
   },
   "outputs": [],
   "source": [
    "emoji_mapping = {\n",
    "    ':)': 'üòÄ',\n",
    "    ':-)': 'üòÄ',\n",
    "    ':(': 'üòû',\n",
    "    ':-(': 'üòû',\n",
    "    ':-/': 'ü´§',\n",
    "    '<3': '‚ù§Ô∏è',\n",
    "    'XD': 'üòÜ',\n",
    "    'xD': 'üòÜ',\n",
    "    'xd': 'üòÜ',\n",
    "    ':D': 'üòÑ',\n",
    "    ':O': 'üò≤',\n",
    "    ';)': 'üòâ',\n",
    "    ':P': 'üòú',\n",
    "    '>:(': 'üò†',\n",
    "    ':-*': 'üòò',\n",
    "    ':*': 'üòò',\n",
    "    'B)': 'üòé',\n",
    "    '>:D': 'üòà',\n",
    "    'O:)': 'üòá',\n",
    "    ':|': 'üòê',\n",
    "    ':S': 'üòñ',\n",
    "    ':X': 'üò∂',\n",
    "    '<(\")': 'üê¶',\n",
    "    '>:O': 'üò±',\n",
    "    '\\\\o/': 'üôå',\n",
    "    '(^_^)/': 'üåü',\n",
    "    '(o_o)/': 'üåú',\n",
    "    '<>_<>': 'üéÆ',\n",
    "    '(>_<)': 'üò£',\n",
    "    '(^_-)': 'üòÑ',\n",
    "    '(^_^)b': 'üëç',\n",
    "    '(~_^)': 'üòÇ',\n",
    "    ':-D': 'üòÅ',\n",
    "    ':|)': 'üòê',\n",
    "    '>:)': 'üòè',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Map emoticons to emoji"
   ],
   "metadata": {
    "id": "8Dw8Cp2NWei6"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "VXp2UNuWU7El"
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "train_path = \"/content/drive/MyDrive/NLP-project/COMET_data/paracomet/dialogue/samsum/dialog_train_split5_collated.json\"\n",
    "\n",
    "with open(train_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        for key, value in data.items():\n",
    "            for k, v in value.items():\n",
    "                for inner_key, inner_value in v.items():\n",
    "                    if inner_key == \"sentence\":\n",
    "                        sentences.append(inner_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ABHozVycWFpH"
   },
   "outputs": [],
   "source": [
    "def extract_emojis(text):\n",
    "    return [char for char in text if char in emoji.EMOJI_DATA]\n",
    "\n",
    "def substitute_emojis(text, emoji_mapping):\n",
    "    for key, value in emoji_mapping.items():\n",
    "        text = text.replace(key, value)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "fmZFQm_BVYnG"
   },
   "outputs": [],
   "source": [
    "# map emoticons to emoji\n",
    "mapped_dialogues = []\n",
    "\n",
    "for s in sentences:\n",
    "  mapped_dialogues.append(substitute_emojis(s, emoji_mapping))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train W2V model"
   ],
   "metadata": {
    "id": "aW4FpqFwX0Ci"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def preparing_data(data_path):\n",
    "    if data_path:\n",
    "        with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            train_data = [line.strip().split() for line in lines]\n",
    "        return train_data\n",
    "    else:\n",
    "        print(\"Error path\")\n",
    "\n",
    "def train_model(size, window, min_count, workers, vocab_size, negative, epochs, train_data):\n",
    "    # train model\n",
    "    print(\"training word2vec\")\n",
    "    model = Word2Vec(\n",
    "        train_data,\n",
    "        vector_size=size,\n",
    "        window=window,\n",
    "        min_count=min_count,\n",
    "        workers=workers,\n",
    "        max_vocab_size=vocab_size,\n",
    "        negative=negative,\n",
    "        epochs=epochs  # Add epochs parameter\n",
    "    )\n",
    "    print(\"saving model\")\n",
    "    model.save(\"word2vec_twitter_data.bin\")\n",
    "    model.wv.save_word2vec_format(\"word2vec.txt\")\n",
    "\n",
    "# Assign values manually\n",
    "dataset_path = \"/content/drive/MyDrive/datasets/twitter_data.txt\"\n",
    "word2vec_size = 300\n",
    "word2vec_window = 5\n",
    "word2vec_min_count = 10\n",
    "word2vec_workers = 4\n",
    "word2vec_vocab_size = None\n",
    "word2vec_negative = 5\n",
    "word2vec_epochs = 20\n",
    "\n",
    "train_data = preparing_data(dataset_path)\n",
    "train_model(\n",
    "    size=word2vec_size,\n",
    "    window=word2vec_window,\n",
    "    min_count=word2vec_min_count,\n",
    "    workers=word2vec_workers,\n",
    "    vocab_size=word2vec_vocab_size,\n",
    "    negative=word2vec_negative,\n",
    "    train_data=train_data,\n",
    "    epochs=word2vec_epochs\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aSghcUzLX693",
    "outputId": "54576955-8f71-49a8-8514-bf967f24a987"
   },
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training word2vec\n",
      "saving model\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Save pre-trained model on drive\n",
    "import shutil\n",
    "dest_folder = \"/content/drive/MyDrive/\"\n",
    "source_folder = f\"/content/word2vec_twitter_data.bin\"\n",
    "shutil.copy(source_folder, dest_folder)"
   ],
   "metadata": {
    "id": "NQfWOYo1GV1Y",
    "outputId": "593146c3-6847-4aa2-baa5-b1bb17c6a986",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    }
   },
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/content/drive/MyDrive/word2vec_twitter_data.bin'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 22
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine-tune on samsum"
   ],
   "metadata": {
    "id": "4qE84B6OcSfK"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dvCEBSESaB_E",
    "outputId": "0b327c47-25e9-4690-8cfd-59ac48721349"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load your new dataset (a list of sentences)\n",
    "new_sentences = mapped_dialogues\n",
    "\n",
    "# Tokenize the sentences into lists of words\n",
    "tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in new_sentences]\n",
    "\n",
    "# Update the vocabulary with the new dataset\n",
    "model.build_vocab(tokenized_sentences, update=True)\n",
    "\n",
    "# Fine-tune the model on the new dataset\n",
    "model.train(tokenized_sentences, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "# Save the fine-tuned model\n",
    "fine_tuned_model_path = '/content/drive/MyDrive/fine_tuned_word2vec_model.bin'\n",
    "model.save(fine_tuned_model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## If you have pre-trained model start here"
   ],
   "metadata": {
    "id": "aT9wrAB-Cifw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model_path = \"/content/drive/MyDrive/word2vec5.bin\"\n",
    "model = Word2Vec.load(model_path)"
   ],
   "metadata": {
    "id": "9D2D8k2FcDob"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "def starts_with_letter(s):\n",
    "    return bool(re.match(r'^[a-zA-Z]', s))"
   ],
   "metadata": {
    "id": "mJqUAdYH7BoU"
   },
   "execution_count": 84,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import string\n",
    "\n",
    "def extract_words(emoji, model, topn, k, threshold):\n",
    "    if emoji in model.wv.key_to_index:\n",
    "        similar_words = model.wv.most_similar(emoji, topn=topn)\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "    # Filter out emojis, punctuation, and short words\n",
    "    result = [item[0] for item in similar_words if (starts_with_letter(item[0]) and  len(item[0]) > 3 and item[1] > threshold) ]\n",
    "\n",
    "    return ', '.join(result[:k])"
   ],
   "metadata": {
    "id": "8NioTLNPIRp6"
   },
   "execution_count": 88,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "extract_words('üéÜ',model,40,3,0.2)"
   ],
   "metadata": {
    "id": "eN5GW_kjIUpZ",
    "outputId": "76e8102a-5d21-4a66-eb5f-bc6cf2e1b8ff",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    }
   },
   "execution_count": 65,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'bonfire, fireworks, firework'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 65
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model.wv.most_similar('üòÖ', topn=40)"
   ],
   "metadata": {
    "id": "X-0xl8WcJUGu"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Json emoji"
   ],
   "metadata": {
    "id": "JT6nKWXSvESG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def replace_with_extraction(sentence, emoji, model, topn, num_words, threshold):\n",
    "    replacement = extract_words(emoji, model, topn, num_words, threshold)\n",
    "\n",
    "    if replacement:\n",
    "        modified_sentence = sentence.replace(emoji, f\"<E>{replacement}<\\E>\")\n",
    "        return modified_sentence\n",
    "    else:\n",
    "        return sentence"
   ],
   "metadata": {
    "id": "b33LlnKN3imA"
   },
   "execution_count": 89,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def substitute_emojis_with_inferred_words(dialogues):\n",
    "\n",
    "    modified_dialogues = []\n",
    "\n",
    "    for sentence in dialogues:\n",
    "      sub_emojies = []\n",
    "      sentence = reduce_consecutive_emojis(sentence)\n",
    "      emoji_in_sentence = extract_emojis(sentence)\n",
    "      modified_sentence = sentence\n",
    "      for emoji in emoji_in_sentence:\n",
    "          modified_sentence = replace_with_extraction(sentence, emoji, model, 40, 3, 0.2)\n",
    "          sub_emojies.append(emoji)\n",
    "      modified_dialogues.append(modified_sentence)\n",
    "\n",
    "    return modified_dialogues"
   ],
   "metadata": {
    "id": "YBvFiIm_vWmS"
   },
   "execution_count": 124,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "def reduce_consecutive_emojis(input_string):\n",
    "    # Create a pattern for the emojis in the list\n",
    "    emoji_pattern = '|'.join(re.escape(emoji) for emoji in emoji.EMOJI_DATA )\n",
    "\n",
    "    # Use regular expression to find consecutive occurrences of the same emoji\n",
    "    pattern = re.compile(f'({emoji_pattern})\\\\1+')\n",
    "\n",
    "    # Replace consecutive emojis with a single instance of that emoji\n",
    "    result_string = pattern.sub(r'\\1', input_string)\n",
    "\n",
    "    return result_string"
   ],
   "metadata": {
    "id": "9SxWKs7H9kTp",
    "outputId": "ecf144b1-02e3-43e0-e472-d445197ba9c0",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 110,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input String: üòäüòäüéâüéâüéâüéâüéâüéâüéâHello! üòÅüòÅ How are you? üòäüòä\n",
      "Output String: üòäüéâHello! üòÅ How are you? üòä\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "preprocessed_sentences = substitute_emojis_with_inferred_words(mapped_dialogues)"
   ],
   "metadata": {
    "id": "amwdNL-qv0VY"
   },
   "execution_count": 150,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "preprocessed_sentences"
   ],
   "metadata": {
    "id": "XJHCoLA00Z56"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def remap_sentences_emoji_codified(sentence, split):\n",
    "    counter = 0\n",
    "    split_str = f'dialog_{split}_split5_collated.json'\n",
    "\n",
    "    with open(f\"/content/drive/MyDrive/NLP-project/COMET_data/paracomet/dialogue/samsum/{split_str}\", 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    new_data = {}\n",
    "    for key, value in data.items():\n",
    "        new_d = {}\n",
    "        for k, v in value.items():\n",
    "            new_value = {}\n",
    "            for inner_key, inner_value in v.items():\n",
    "                if inner_key == \"sentence\":\n",
    "                    new_value[inner_key] = sentence[counter]\n",
    "                    counter += 1\n",
    "                else:\n",
    "                    new_value[inner_key] = inner_value\n",
    "            new_d[k] = new_value\n",
    "        new_data[key] = new_d\n",
    "\n",
    "    new_json_file_path = f'preprocessed_v2_dialog_{split}_split5_collated.json'\n",
    "    with open(new_json_file_path, 'w') as new_file:\n",
    "        json.dump(new_data, new_file, indent=2)"
   ],
   "metadata": {
    "id": "9jSspRbV1dRz"
   },
   "execution_count": 126,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "split = \"train\""
   ],
   "metadata": {
    "id": "fDNGRQBy2NTb"
   },
   "execution_count": 151,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "remap_sentences_emoji_codified(preprocessed_sentences, split)"
   ],
   "metadata": {
    "id": "bbcGpUoi1iDg"
   },
   "execution_count": 152,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# move file to drive!\n",
    "import shutil\n",
    "dest_folder = \"/content/drive/MyDrive/NLP-project/COMET_data/paracomet/dialogue/samsum/emoji_w2v/\"\n",
    "source_folder = f\"/content/preprocessed_v2_dialog_{split}_split5_collated.json\"\n",
    "shutil.copy(source_folder, dest_folder)"
   ],
   "metadata": {
    "id": "ToN7b3ZK2DzH",
    "outputId": "d1c69d83-2432-4d9a-f739-593ed85f81f1",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    }
   },
   "execution_count": 153,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/content/drive/MyDrive/NLP-project/COMET_data/paracomet/dialogue/samsum/emoji_w2v/preprocessed_v2_dialog_train_split5_collated.json'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 153
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMoiPN5beclJ"
   },
   "source": [
    "## PCA & Plotting in 2d space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-0BsWKmzd77o"
   },
   "outputs": [],
   "source": [
    "emoji_embeddings_dict = {}\n",
    "\n",
    "# Populate the dictionary with emoji embeddings\n",
    "for emoji in emoji.EMOJI_DATA:\n",
    "    if emoji in model.wv:\n",
    "        emoji_embeddings_dict[emoji] = model.wv[emoji]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cEW4Yxq7eliO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from imojify import imojify\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "\n",
    "\n",
    "def offset_image(cords, emoji, ax):\n",
    "    img = plt.imread(imojify.get_img_path(emoji))\n",
    "    im = OffsetImage(img, zoom=0.12)\n",
    "    im.image.axes = ax\n",
    "    ab = AnnotationBbox(im, (cords[0], cords[1]),  frameon=False, pad=0)\n",
    "    ax.add_artist(ab)\n",
    "\n",
    "\n",
    "# Extract emoji embeddings and labels\n",
    "emoji_labels = list(emoji_embeddings_dict.keys())\n",
    "emoji_embeddings = np.array(list(emoji_embeddings_dict.values()))\n",
    "\n",
    "# Perform PCA to reduce dimensions to 2D\n",
    "pca = PCA(n_components=2)\n",
    "emoji_2d = pca.fit_transform(emoji_embeddings)\n",
    "\n",
    "# Plot the 2D embeddings\n",
    "fig, ax = plt.subplots(figsize=(100, 60))\n",
    "ax.scatter(emoji_2d[:, 0], emoji_2d[:, 1])\n",
    "\n",
    "# Annotate the points with emojis\n",
    "for i, label in enumerate(emoji_labels):\n",
    "    offset_image([emoji_2d[i, 0], emoji_2d[i, 1]], label, ax)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig(\"emoji.png\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "Cd-QdGUpU2uF",
    "ktRezsj-Wb9x",
    "8Dw8Cp2NWei6",
    "aW4FpqFwX0Ci",
    "4qE84B6OcSfK"
   ],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
