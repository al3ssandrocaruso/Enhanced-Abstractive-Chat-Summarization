{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7Im1R263VDH"
   },
   "source": [
    "# KeyBERT for key extraction from sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSwxxRu73hm0"
   },
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O45RAq_33Uj3"
   },
   "outputs": [],
   "source": [
    "!pip install keybert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svm6sBhvGmPK"
   },
   "source": [
    "## SAMsum implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18731,
     "status": "ok",
     "timestamp": 1702065361872,
     "user": {
      "displayName": "ValerioNLP",
      "userId": "00629352364637323822"
     },
     "user_tz": -60
    },
    "id": "YdbzjjyCGvcp",
    "outputId": "be5cd188-69b8-4539-d6c2-e2643ff434d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-HV5vKHzIAJR"
   },
   "outputs": [],
   "source": [
    "from keybert import KeyBERT\n",
    "kw_model = KeyBERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1702065391128,
     "user": {
      "displayName": "ValerioNLP",
      "userId": "00629352364637323822"
     },
     "user_tz": -60
    },
    "id": "Vc9hYj-AJ6K1"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_between_tags(sentence):\n",
    "    \"\"\"\n",
    "        given an imput string remove the emoji part marked by <E>...</E>\n",
    "    \"\"\"\n",
    "    pattern = r'<E>.*?<\\\\E>'\n",
    "    result = re.sub(pattern, '', sentence)\n",
    "    return result\n",
    "\n",
    "def extract_text_after_said(sentence):\n",
    "    \"\"\"\n",
    "        given an imput string remove the /said part which is always present in all\n",
    "        the sentences\n",
    "    \"\"\"\n",
    "    pattern = r'said \"(.*?)\"'\n",
    "    match = re.search(pattern, sentence)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return sentence\n",
    "\n",
    "def order_keywords(phrase, keys):\n",
    "    \"\"\"\n",
    "        given a list of keys extracted by keyBERT and the original phrase\n",
    "        the function returns the key sorted as in the original phrase\n",
    "    \"\"\"\n",
    "    keyword_positions = {key: phrase.find(key) for key in keys}\n",
    "    sorted_keys = sorted(keys, key=lambda key: keyword_positions[key])\n",
    "    return sorted_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 301,
     "status": "ok",
     "timestamp": 1702065393605,
     "user": {
      "displayName": "ValerioNLP",
      "userId": "00629352364637323822"
     },
     "user_tz": -60
    },
    "id": "a4xRTHu7H61w"
   },
   "outputs": [],
   "source": [
    "def extract_keywords(sentence, thr):\n",
    "    sentence1 = remove_between_tags(sentence)\n",
    "    sentence = extract_text_after_said(sentence1)\n",
    "\n",
    "    extracted_keywords = kw_model.extract_keywords(sentence, keyphrase_ngram_range=(1, 1), stop_words='english', use_maxsum=True)\n",
    "    keywords_over_thresh = [keyword[0] for keyword in extracted_keywords if keyword[1]>thr]\n",
    "    keywords_over_thresh = order_keywords(sentence, keywords_over_thresh)\n",
    "\n",
    "    if len(keywords_over_thresh)!=0:\n",
    "        return \"<K>\" + ' '.join(keywords_over_thresh) + \"<\\K>\"\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 393,
     "status": "ok",
     "timestamp": 1702065399006,
     "user": {
      "displayName": "ValerioNLP",
      "userId": "00629352364637323822"
     },
     "user_tz": -60
    },
    "id": "ZlRICCdnUeVC"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "def get_keyword_from_json_store_new_file(split):\n",
    "\n",
    "    split_str = f'preprocessed_dialog_{split}_split5_collated.json'\n",
    "\n",
    "    with open(f\"/content/drive/MyDrive/NLP-project/COMET_data/paracomet/dialogue/samsum/{split_str}\", 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "        new_data = {}\n",
    "        for key, value in data.items():\n",
    "            new_d = {}\n",
    "            for k, v in value.items():\n",
    "                new_value = {}\n",
    "                for inner_key, inner_value in v.items():\n",
    "                    if inner_key == \"sentence\":\n",
    "                        new_value[inner_key] = extract_keywords(inner_value, 0.35) + inner_value\n",
    "                    else:\n",
    "                        new_value[inner_key] = inner_value\n",
    "                new_d[k] = new_value\n",
    "            new_data[key] = new_d\n",
    "\n",
    "    new_json_file_path = f'preprocessed_keywords_dialog_{split}_split5_collated.json'\n",
    "    with open(new_json_file_path, 'w') as new_file:\n",
    "        json.dump(new_data, new_file, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "v3NdSoFTL7Pi"
   },
   "outputs": [],
   "source": [
    "split = \"train\"\n",
    "get_keyword_from_json_store_new_file(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SGb21ssEM-wa"
   },
   "outputs": [],
   "source": [
    "split = [\"train\", \"test\", \"validation\"]\n",
    "for s in split:\n",
    "    get_keyword_from_json_store_new_file(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TUqwcmrVPlJj"
   },
   "outputs": [],
   "source": [
    "# move file to drive!\n",
    "import shutil\n",
    "dest_folder = \"/content/drive/MyDrive/\"\n",
    "source_folder = f\"/content/preprocessed_keyword_dialog_{split}_split5_collated.json\"\n",
    "shutil.copy(source_folder, dest_folder)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPC/v9O5rbqJncp8fw8MQYa",
   "collapsed_sections": [
    "NlzmEGok3rLQ"
   ],
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
