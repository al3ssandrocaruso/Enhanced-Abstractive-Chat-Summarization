{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "uYje3IcZeE4Q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/datasets/slang.csv')\n",
        "abbreviation_dict = dict(zip(df['Abbreviation'], df['Expansion']))\n",
        "\n",
        "def substitute_abbreviations(sentence):\n",
        "    words = re.findall(r'\\b\\w+\\b|[^\\w\\s]', sentence)\n",
        "    substituted_sentence = ' '.join(abbreviation_dict.get(word.upper(), abbreviation_dict.get(word.lower(), word)) for word in words)\n",
        "    return substituted_sentence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split = \"train\""
      ],
      "metadata": {
        "id": "krkwTWb_ttWP"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def get_keyword_from_json_store_new_file(split):\n",
        "\n",
        "    split_str = f'preprocessed_v2_dialog_{split}_split5_collated.json'\n",
        "\n",
        "    with open(f\"/content/drive/MyDrive/NLP-project/COMET_data/paracomet/dialogue/samsum/emoji_w2v/{split_str}\", 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "        new_data = {}\n",
        "        for key, value in data.items():\n",
        "            new_d = {}\n",
        "            for k, v in value.items():\n",
        "                new_value = {}\n",
        "                for inner_key, inner_value in v.items():\n",
        "                    if inner_key == \"sentence\":\n",
        "                        new_value[inner_key] = substitute_abbreviations(inner_value)\n",
        "                    else:\n",
        "                        new_value[inner_key] = inner_value\n",
        "                new_d[k] = new_value\n",
        "            new_data[key] = new_d\n",
        "\n",
        "    new_json_file_path = f'preprocessed_keywords_slang_emoji_dialog_{split}_split5_collated.json'\n",
        "    with open(new_json_file_path, 'w') as new_file:\n",
        "        json.dump(new_data, new_file, indent=2)\n"
      ],
      "metadata": {
        "id": "-6qOeZvltl9U"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_keyword_from_json_store_new_file(split)"
      ],
      "metadata": {
        "id": "N_1w4p1zyqTo"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# move file to drive!\n",
        "import shutil\n",
        "dest_folder = \"/content/drive/MyDrive/COMET_data/paracomet/dialogue/samsum/keyword_emoji_slang\"\n",
        "source_folder = f\"/content/preprocessed_keywords_slang_emoji_dialog_{split}_split5_collated.json\"\n",
        "shutil.copy(source_folder, dest_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "l-L9JzPEzDeR",
        "outputId": "58f9b469-ffef-425a-dbd9-37faafe0fb21"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/NLP-project/COMET_data/paracomet/dialogue/samsum/keyword_emoji_slang/preprocessed_keywords_slang_emoji_dialog_train_split5_collated.json'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    }
  ]
}